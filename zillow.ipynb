{
  "cells": [
    {},
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# Import Data\n",
        "features = pd.read_csv(\"../input/properties_2016.csv\", nrows=100000)\n",
        "labels = pd.read_csv(\"../input/train_2016_v2.csv\", nrows=100000)\n",
        "labels.head()\n",
        "\n",
        "# Drop properties where all features are NaNs\n",
        "features.dropna(axis = 'index', how = 'all')\n",
        "\n",
        "# Join Data\n",
        "df = pd.DataFrame.merge(features,labels,on=\"parcelid\")\n",
        "df.head()\n",
        "\n",
        "# Drop features where all properties are NaNs\n",
        "df.dropna(axis = 'columns', how = 'all')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# Convert to Numpy Array\n",
        "features = df.as_matrix(columns=[\"basementsqft\",\n",
        "                                 \"bathroomcnt\",\"bedroomcnt\",\n",
        "                                 \"lotsizesquarefeet\",\n",
        "                                 \"calculatedfinishedsquarefeet\",\n",
        "                                 \"fireplacecnt\",\n",
        "                                 \"garagecarcnt\",\n",
        "                                 \"garagetotalsqft\",\n",
        "                                 \"poolcnt\",\n",
        "                                 \"poolsizesum\",\n",
        "                                 \"unitcnt\",\n",
        "                                 \"numberofstories\",\n",
        "                                 \"structuretaxvaluedollarcnt\",\n",
        "                                 \"landtaxvaluedollarcnt\",\n",
        "                                 \"taxamount\"\n",
        "                                 ])\n",
        "features = np.nan_to_num(features)\n",
        "labels = df.as_matrix(columns=[\"logerror\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = \\\n",
        "    train_test_split(features, labels, test_size=0.30, random_state=42)\n",
        "#print(len(features_train))\n",
        "print(len(labels_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# First look\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regr = LinearRegression()\n",
        "regr = regr.fit(features_train,labels_train)\n",
        "mse = mean_squared_error(regr.predict(features_test), labels_test)\n",
        "print(\"model ceofficients: \", regr.coef_)\n",
        "print(\"mean square error: \",mse)\n",
        "print(\"Variance score: \",regr.score(features_test,labels_test))\n",
        "\n",
        "# Plot outputs\n",
        "#plt.scatter(features_test, labels_test,  color='black')\n",
        "plt.plot(features_test, regr.predict(features_test), color='blue',\n",
        "         linewidth=3)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# Create pipeline for analysis\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "#from sklearn.feature_selection import SelectKBest\n",
        "#from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.linear_model import (LinearRegression, TheilSenRegressor, \n",
        "                                  RANSACRegressor, HuberRegressor)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "estimators = [('OLS', LinearRegression()),\n",
        "              ('Theil-Sen', TheilSenRegressor(random_state=42)),\n",
        "              ('RANSAC', RANSACRegressor(random_state=42)),\n",
        "              ('HuberRegressor', HuberRegressor())]\n",
        "\n",
        "pipe = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
        "#print(pipe.steps[1])\n",
        "\n",
        "params = dict(polynomialfeatures__degree = range(3, 4))\n",
        "\n",
        "cv = StratifiedShuffleSplit(n_splits=10, test_size = 0.1, random_state = 42)\n",
        "gs = GridSearchCV(pipe, param_grid=params, cv=cv, scoring='f1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# What do the labels look like? Look pretty normally distributed. Maybe one outlier.\n",
        "plt.hist(labels_train, bins=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      },
      "outputs": [],
      "source": [
        "# Define classifier\n",
        "gs = gs.fit(features_train,labels_train)\n",
        "clf = gs.best_estimator_\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "<span>Python 3.6.1</span><span class=\"fa fa-info-circle notebook-info-modal__info-icon\"></span>"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}